{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import requests\n",
    "import zipfile\n",
    "import io\n",
    "import wget\n",
    "import nibabel as nib\n",
    "from scipy import ndimage\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MosmedDataset(Dataset):\n",
    "    def __init__(self, download: bool = False, save_path: str = \".\", train: bool = True):\n",
    "        if download:\n",
    "            ct_link = {\n",
    "                \"CT-0\": \"https://github.com/hasibzunair/3D-image-classification-tutorial/releases/download/v0.2/CT-0.zip\",\n",
    "                \"CT-23\": \"https://github.com/hasibzunair/3D-image-classification-tutorial/releases/download/v0.2/CT-23.zip\"\n",
    "            }\n",
    "            for key in ct_link.keys():\n",
    "                wget.download(ct_link[key], save_path)\n",
    "                with zipfile.ZipFile(os.path.join(save_path, ct_link + \".zip\"), \"r\") as z_fp:\n",
    "                    z_fp.extractall(os.path.join(save_path))\n",
    "\n",
    "        volume_dir = \"/home/data/01_SSD4TB/suzy/datasets/public-datasets/mosmed\"\n",
    "        normal_scans = [os.path.join(volume_dir, \"CT-0\", fname)\n",
    "                        for fname in os.listdir(os.path.join(volume_dir, \"CT-0\"))]\n",
    "        abnormal_scans = [os.path.join(volume_dir, \"CT-23\", fname)\n",
    "                          for fname in os.listdir(os.path.join(volume_dir, \"CT-23\"))]\n",
    "        normal_labels = [[0] for _ in range(len(normal_scans))]\n",
    "        abnormal_labels = [[1] for _ in range(len(abnormal_scans))]\n",
    "\n",
    "        normal = list(zip(normal_scans, normal_labels))\n",
    "        abnormal = list(zip(abnormal_scans, abnormal_labels))\n",
    "\n",
    "        all_list = normal + abnormal\n",
    "        train_files, test_files = train_test_split(all_list, test_size=0.3)\n",
    "        if train:\n",
    "            self.fnames = train_files\n",
    "        else:\n",
    "            self.fnames = test_files\n",
    "\n",
    "    def normalize_volume(self, volume):\n",
    "        _min, _max = -1000, 400\n",
    "        volume[volume < _min] = _min\n",
    "        volume[volume > _max] = _max\n",
    "        volume = (volume - _min) / (_max - _min)\n",
    "        volume = volume.astype(\"float32\")\n",
    "        return volume\n",
    "\n",
    "    def resize_volume(self, volume):\n",
    "        target_d, target_w, target_h = 64, 128, 128\n",
    "        curr_d, curr_w, curr_h = volume.shape[-1], volume.shape[0], volume.shape[1]\n",
    "\n",
    "        d = curr_d / target_d\n",
    "        w = curr_w / target_w\n",
    "        h = curr_h / target_h\n",
    "\n",
    "        d_factor = 1 / d\n",
    "        w_factor = 1 / w\n",
    "        h_factor = 1 / h\n",
    "\n",
    "        volume = ndimage.rotate(volume, 90, reshape=False)\n",
    "        volume = ndimage.zoom(volume, (w_factor, h_factor, d_factor), order=1)\n",
    "\n",
    "        return volume\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        volume = nib.load(self.fnames[idx][0])\n",
    "        label = self.fnames[idx][-1][0]\n",
    "        volume = volume.get_fdata()\n",
    "        volume = self.normalize_volume(volume)\n",
    "        volume = self.resize_volume(volume)\n",
    "        volume = torch.from_numpy(volume)\n",
    "        volume = volume.unsqueeze(3)\n",
    "        volume = volume.permute(3,0,1,2)\n",
    "        label = torch.tensor(label, dtype=torch.float32)\n",
    "        return volume, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.fnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MosmedDataset(download=False,  train=True)\n",
    "valid_dataset = MosmedDataset(download=False,  train=False)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, num_workers=0)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=4, shuffle=True, num_workers=0)\n",
    "\n",
    "volumes, labels = next(iter(train_loader))\n",
    "volume = volumes[0]\n",
    "print(\"Dimension of the CT scan is:\", volume.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.squeeze(volume[:, :, 30]), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_slices(num_rows, num_columns, width, height, data):\n",
    "    \"\"\"Plot a montage of 20 CT slices\"\"\"\n",
    "    data = np.rot90(np.array(data))\n",
    "    data = np.transpose(data)\n",
    "    data = np.reshape(data, (num_rows, num_columns, width, height))\n",
    "    rows_data, columns_data = data.shape[0], data.shape[1]\n",
    "    heights = [slc[0].shape[0] for slc in data]\n",
    "    widths = [slc.shape[1] for slc in data[0]]\n",
    "    fig_width = 12.0\n",
    "    fig_height = fig_width * sum(heights) / sum(widths)\n",
    "    f, axarr = plt.subplots(\n",
    "        rows_data,\n",
    "        columns_data,\n",
    "        figsize=(fig_width, fig_height),\n",
    "        gridspec_kw={\"height_ratios\": heights},\n",
    "    )\n",
    "    for i in range(rows_data):\n",
    "        for j in range(columns_data):\n",
    "            axarr[i, j].imshow(data[i][j], cmap=\"gray\")\n",
    "            axarr[i, j].axis(\"off\")\n",
    "    plt.subplots_adjust(wspace=0, hspace=0, left=0, right=1, bottom=0, top=1)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Visualize montage of slices.\n",
    "# 4 rows and 10 columns for 100 slices of the CT scan.\n",
    "plot_slices(4, 10, 128, 128, volume[:, :, :40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters = [1,64,64,128,256]\n",
    "\n",
    "class ConvNet3D(nn.Module):\n",
    "    def __init__(self, filters):\n",
    "        super().__init__()\n",
    "\n",
    "        self.maxpool = nn.MaxPool3d(kernel_size=2)\n",
    "\n",
    "        self.conv1 = nn.Conv3d(in_channels=filters[0], out_channels=filters[1], kernel_size=3)\n",
    "        self.bn1 = nn.BatchNorm3d(filters[1])\n",
    "\n",
    "        self.conv2 = nn.Conv3d(in_channels=filters[1], out_channels=filters[2], kernel_size=3)\n",
    "        self.bn2 = nn.BatchNorm3d(filters[2])\n",
    "\n",
    "        self.conv3 = nn.Conv3d(in_channels=filters[2], out_channels=filters[3], kernel_size=3)\n",
    "        self.bn3 = nn.BatchNorm3d(filters[3])\n",
    "\n",
    "        self.conv4 = nn.Conv3d(in_channels=filters[3], out_channels=filters[4], kernel_size=3)\n",
    "        self.bn4 = nn.BatchNorm3d(filters[4])\n",
    "\n",
    "        self.gap = nn.AvgPool3d(kernel_size=2)\n",
    "        self.dense = nn.Linear(256*3*3,512)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.fc = nn.Linear(512,1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.conv1(x))\n",
    "        out = self.bn1(self.maxpool(out))\n",
    "\n",
    "        out = F.relu(self.conv2(out))\n",
    "        out = self.bn2(self.maxpool(out))\n",
    "\n",
    "        out = F.relu(self.conv3(out))\n",
    "        out = self.bn3(self.maxpool(out))\n",
    "\n",
    "        out = F.relu(self.conv4(out))\n",
    "        out = self.bn4(self.maxpool(out))\n",
    "\n",
    "        out = self.gap(out)\n",
    "        out = self.dense(out.view(-1, 256*3*3))\n",
    "        out = self.dropout(out)\n",
    "        out = torch.sigmoid(self.fc(out))\n",
    "\n",
    "        return out.view(-1)\n",
    "\n",
    "sample_tensor = torch.zeros(4, 1, 128, 128, 64)\n",
    "model = ConvNet3D(filters)\n",
    "out = model(sample_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.0001\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = lr)\n",
    "epochs = 15\n",
    "\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = model.to(device)\n",
    "log_step = 1\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model = model.train()\n",
    "    train_running_loss = 0.0\n",
    "    valid_running_loss = 0.0\n",
    "    batch_count = 0\n",
    "    \n",
    "    print(f\"Epoch: {epoch+1}\")\n",
    "\n",
    "    for i, batch in enumerate(train_loader):\n",
    "        img, label = batch[0], batch[-1]\n",
    "        img, label = img.to(device), label.to(device)\n",
    "        output = model(img)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        #print(output.dtype, label.dtype)\n",
    "        loss = criterion(output, label)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_running_loss += loss.item()\n",
    "        \n",
    "        if i % log_step == 0:\n",
    "            print(f\"Batch: {i}, train loss: {train_running_loss / log_step}\")\n",
    "            train_running_loss = 0.0\n",
    "   \n",
    "   # print(f\"Train loss: {train_running_loss / len(train_dataset)}\")\n",
    "    \n",
    "    # model = model.eval()\n",
    "    # with torch.no_grad():\n",
    "    #     for i, batch in enumerate(valid_loader):\n",
    "    #         img, label = batch[0], batch[-1]\n",
    "    #         img, label = img.to(device), label.to(device)\n",
    "    #         output = model(img)\n",
    "    #         loss = criterion(output, label)\n",
    "    #         valid_running_loss += loss.item()\n",
    "            \n",
    "    # print(f\"Valid loss: {valid_running_loss / len(valid_dataset)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('fexperimental')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a0281dda4d5b6183a762146ec650959e8c924da681b3dae9eacdf6ec4577ba62"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
